import google.generativeai as genai
from src.config import GEMINI_API_KEY
from src.llm.system_prompt import PSEUDOCODE_GRAMMAR_PROMPT

class GeminiService:
    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("No se encontr√≥ la GEMINI_API_KEY en el archivo .env")
        
        try:
            genai.configure(api_key=GEMINI_API_KEY)
            
            # --- SELECCI√ìN DIN√ÅMICA DEL MEJOR MODELO ---
            self.model = self._find_best_model()
            
        except Exception as e:
            print(f"Error fatal configurando Gemini: {e}")
            # Fallback de emergencia para no romper la app al iniciar
            self.model = None 

    def _find_best_model(self):
        """
        Busca en la API los modelos disponibles y selecciona el mejor.
        Prioridad: Flash -> 1.5 Pro -> 1.0 Pro
        """
        try:
            print("üîç Buscando modelos disponibles en tu cuenta...")
            available_models = []
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    available_models.append(m.name)
            
            # Lista de prioridad (del m√°s r√°pido al m√°s est√°ndar)
            priorities = [
                'gemini-1.5-flash',
                'gemini-1.5-pro',
                'gemini-1.0-pro',
                'gemini-pro'
            ]
            
            selected_name = None
            
            # 1. Intentar coincidencia exacta o parcial
            for priority in priorities:
                for avail in available_models:
                    if priority in avail:
                        selected_name = avail
                        break
                if selected_name: break
            
            # 2. Si no encuentra ninguno de la lista, toma el primero disponible
            if not selected_name and available_models:
                selected_name = available_models[0]
            
            # 3. Fallback final (hardcoded)
            if not selected_name:
                selected_name = 'gemini-pro'

            print(f"‚úÖ Modelo seleccionado: {selected_name}")
            return genai.GenerativeModel(selected_name)

        except Exception as e:
            print(f"‚ö†Ô∏è Error listando modelos ({e}), intentando 'gemini-pro' por defecto.")
            return genai.GenerativeModel('gemini-pro')

    def generate_algorithm_code(self, user_request: str) -> str:
        """
        Solicita a Gemini que genere un algoritmo basado en la descripci√≥n del usuario.
        """
        if not self.model:
            return "Error: No hay conexi√≥n con el modelo de IA."

        full_prompt = f"{PSEUDOCODE_GRAMMAR_PROMPT}\n\nSOLICITUD DEL USUARIO: {user_request}\n\nC√ìDIGO GENERADO:"
        
        try:
            response = self.model.generate_content(full_prompt)
            
            if not response.text:
                return "Error: Gemini gener√≥ una respuesta vac√≠a."
                
            code = response.text
            # Limpieza b√°sica de markdown
            code = code.replace("```javascript", "").replace("```python", "").replace("```", "").strip()
            return code
            
        except Exception as e:
            return f"Error Generando C√≥digo: {str(e)}\nVerifica tu API Key o cuota."

    def get_complexity_opinion(self, code: str) -> str:
        """
        Consulta la complejidad al LLM.
        """
        if not self.model:
            return "Error de conexi√≥n IA."

        prompt = f"""
        Analiza el siguiente pseudoc√≥digo y dime cu√°l es su complejidad temporal usando la notaci√≥n con una cota fuerte (Theta) y una breve justificaci√≥n de 1 l√≠nea.
        
        C√ìDIGO:
        {code}
        
        FORMATO RESPUESTA:
        Œò(...) - Justificaci√≥n
        """
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            return "No se pudo obtener opini√≥n."